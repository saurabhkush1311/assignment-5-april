{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "175a14b8-45b9-4f89-9863-327abcb01836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Import necessary libraries\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport seaborn as sns\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.tree import DecisionTreeClassifier\\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\\nfrom sklearn.model_selection import cross_val_score\\nfrom sklearn import tree\\n\\n# Q1: Import the dataset and examine the variables\\nfile_path = \\'path_to_diabetes.csv\\'  # Replace with the actual path\\ndiabetes_data = pd.read_csv(file_path)\\n\\n# Display the first few rows of the dataset\\nprint(diabetes_data.head())\\n\\n# Descriptive statistics\\nprint(diabetes_data.describe())\\n\\n# Visualizations\\nsns.pairplot(diabetes_data, hue=\\'Outcome\\', diag_kind=\\'kde\\')\\nplt.show()\\n\\n# Q2: Preprocess the data\\n# Handle missing values\\ndiabetes_data.fillna(diabetes_data.median(), inplace=True)\\n\\n# Remove outliers (using z-score as an example)\\nz_scores = (diabetes_data - diabetes_data.mean()) / diabetes_data.std()\\ndiabetes_data = diabetes_data[(z_scores < 3).all(axis=1)]\\n\\n# Transform categorical variables into dummy variables if necessary\\n\\n# Q3: Split the dataset\\nX = diabetes_data.drop(\\'Outcome\\', axis=1)\\ny = diabetes_data[\\'Outcome\\']\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Q4: Train the decision tree model\\ndt_model = DecisionTreeClassifier()\\ncross_val_accuracy = cross_val_score(dt_model, X_train, y_train, cv=5, scoring=\\'accuracy\\')\\nprint(\"Cross-Validation Accuracy:\", cross_val_accuracy.mean())\\n\\n# Q5: Evaluate the performance of the model\\ndt_model.fit(X_train, y_train)\\ny_pred = dt_model.predict(X_test)\\n\\n# Metrics\\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\\nprint(\"Precision:\", precision_score(y_test, y_pred))\\nprint(\"Recall:\", recall_score(y_test, y_pred))\\nprint(\"F1 Score:\", f1_score(y_test, y_pred))\\n\\n# Confusion Matrix\\nconf_matrix = confusion_matrix(y_test, y_pred)\\nsns.heatmap(conf_matrix, annot=True, fmt=\\'d\\', cmap=\\'Blues\\')\\nplt.xlabel(\\'Predicted\\')\\nplt.ylabel(\\'True\\')\\nplt.show()\\n\\n# ROC Curve\\nfpr, tpr, thresholds = roc_curve(y_test, dt_model.predict_proba(X_test)[:, 1])\\nplt.plot(fpr, tpr, label=\\'Decision Tree\\')\\nplt.xlabel(\\'False Positive Rate\\')\\nplt.ylabel(\\'True Positive Rate\\')\\nplt.legend()\\nplt.show()\\n\\n# AUC Score\\nprint(\"AUC Score:\", roc_auc_score(y_test, dt_model.predict_proba(X_test)[:, 1]))\\n\\n# Q6: Interpret the decision tree\\nplt.figure(figsize=(15, 10))\\ntree.plot_tree(dt_model, feature_names=X.columns, class_names=[\\'Non-Diabetic\\', \\'Diabetic\\'], filled=True, rounded=True)\\nplt.show()\\n\\n# Q7: Validate the decision tree model (sensitivity analysis and scenario testing)\\n# Apply the model to new data or introduce changes to the dataset/environment\\n# Explore the impact of variations in input features on model predictions\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "# Q1: Import the dataset and examine the variables\n",
    "file_path = 'path_to_diabetes.csv'  # Replace with the actual path\n",
    "diabetes_data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(diabetes_data.head())\n",
    "\n",
    "# Descriptive statistics\n",
    "print(diabetes_data.describe())\n",
    "\n",
    "# Visualizations\n",
    "sns.pairplot(diabetes_data, hue='Outcome', diag_kind='kde')\n",
    "plt.show()\n",
    "\n",
    "# Q2: Preprocess the data\n",
    "# Handle missing values\n",
    "diabetes_data.fillna(diabetes_data.median(), inplace=True)\n",
    "\n",
    "# Remove outliers (using z-score as an example)\n",
    "z_scores = (diabetes_data - diabetes_data.mean()) / diabetes_data.std()\n",
    "diabetes_data = diabetes_data[(z_scores < 3).all(axis=1)]\n",
    "\n",
    "# Transform categorical variables into dummy variables if necessary\n",
    "\n",
    "# Q3: Split the dataset\n",
    "X = diabetes_data.drop('Outcome', axis=1)\n",
    "y = diabetes_data['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Q4: Train the decision tree model\n",
    "dt_model = DecisionTreeClassifier()\n",
    "cross_val_accuracy = cross_val_score(dt_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy:\", cross_val_accuracy.mean())\n",
    "\n",
    "# Q5: Evaluate the performance of the model\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred = dt_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, dt_model.predict_proba(X_test)[:, 1])\n",
    "plt.plot(fpr, tpr, label='Decision Tree')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# AUC Score\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, dt_model.predict_proba(X_test)[:, 1]))\n",
    "\n",
    "# Q6: Interpret the decision tree\n",
    "plt.figure(figsize=(15, 10))\n",
    "tree.plot_tree(dt_model, feature_names=X.columns, class_names=['Non-Diabetic', 'Diabetic'], filled=True, rounded=True)\n",
    "plt.show()\n",
    "\n",
    "# Q7: Validate the decision tree model (sensitivity analysis and scenario testing)\n",
    "# Apply the model to new data or introduce changes to the dataset/environment\n",
    "# Explore the impact of variations in input features on model predictions\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29af253-b89f-47a8-ae7e-21f5a0dbd458",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
